---
title: 'R: filtering with NA values'
author: Riinu
date: '2020-02-27'
slug: r-filtering-with-na-values
thumbnailImage: /img/thumbnails/na.png
categories: [R]
tags: [wrangling, dplyr, janitor]
output: md_document
---

NA - Not Available/Not applicable is R's way of denoting empty or missing values. When doing comparisons - such as equal to, greater than, etc. -  extra care and thought needs to go into how missing values (NAs) are handled.
More explanations about this can be found in the Chapter 2: R basics of our book that is freely available at the [HealthyR website](https://healthyr.surgicalinformatics.org/) 

This post lists a couple of different ways of keeping or discarding rows based on how important the variables with missing values are to you.


For example, I want to keep rows that have a value for `important_a` and/or `important_b` (so rows 1, 3, 4).
I don't care whether `whatever_c` is empty or not, but I do want to keep it.

```{r, message=FALSE}
library(tidyverse)

mydata  = tibble(important_a = c("Value", NA, "Value", NA, NA),
                 important_b = c(NA, NA, "Value", "Value", NA),
                 whatever_c  = c(NA, "Value", NA, NA, NA))

mydata %>% knitr::kable()
```



Functions for missing values that are very useful, but don't do what I want are:

(1) This keeps complete cases based on all columns:
```{r}
mydata %>% 
  drop_na()
```

(Returns 0 as we don't have rows where all 3 columns have a value).

(2) This keeps complete cases based on specified columns:

```{r}
mydata %>% 
  drop_na(important_a, important_b)
```
This only keeps the row where both a and b have a value.


(3) This keeps rows that have a value in any column:

```{r}
mydata %>% 
  filter_all(any_vars(! is.na(.)))
```


The third example is better achieved using the janitor package:

```{r, message = FALSE}
mydata %>% 
  janitor::remove_empty()
```

Now, (3) is pretty close, but still, I'm not interested in row 2 - where both a and b are empty but c has a value (which is why it's kept).

(4) Simple solution

A quick solution is to use `! is.na()` for each variable inside a `filter()`:

```{r}
mydata %>% 
  filter(! is.na(important_a) | ! is.na(important_b))
```

And this is definitely what I do when I only have a couple of these variables. But if you have tens, then the filtering logic becomes horrendously long and it's easy to miss one out/make a mistake.

(5) Powerful solution:

A scalable solution is to use `filter_at()` with `vars()` with a select helper (e.g., `starts with()`), and then the `any_vars(! is.na(.))` that was introduced in (3).

```{r}
mydata %>% 
  filter_at(vars(starts_with("important_")), any_vars(! is.na(.)))
```


